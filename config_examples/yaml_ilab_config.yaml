model:
  chat:
    context: default
    greedy_mode: false
    logs_dir: /home/ali/.local/share/instructlab/chatlogs
    max_tokens:
    model: /home/ali/.cache/instructlab/models/merlinite-7b-lab-Q4_K_M.gguf
    session:
    vi_mode: false
    visible_overflow: true
  serve:
    backend: null
    chat_template: null
    host_port: 127.0.0.1:8000
    llama_cpp_gpu_layers: -1
    llama_cpp_llm_family: ''
    llama_cpp_max_ctx_size: 4096
    model_path: /home/ali/.cache/instructlab/models/merlinite-7b-lab-Q4_K_M.gguf
    vllm_gpus: null
    vllm_llm_family: ''
    vllm_max_startup_attempts: 120
    vllm_args: []
